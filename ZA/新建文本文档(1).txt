-----------------------------------------------------------------------------------------------------------------
java

创建一个线程的两种方法：
1.需要从Java.lang.Thread类派生一个新的线程类，重载它的run()方法； 
2.实现Runnalbe接口，重载Runnalbe接口中的run()方法。

为什么有两种实现方法？
1.如果自定义类必须扩展其他的类，那么就可以使用实现Runnable接口的方法来定义该类为线程类，这样就可以避免Java单继承所带来的局限性。
2.使用实现Runnable接口的方式创建的线程可以处理同一资源，从而实现资源的共享

两种实现方法的区别？
1.Thread：利用扩展Thread类创建的多个线程，虽然执行的是相同的代码，但彼此相互独立，且各自拥有自己的资源，互不干扰
2.Runnable：如果现实问题中要求必须创建多个线程来执行同一任务，而且这多个线程之间还将共享同一个资源，那么就可以使用实现Runnable接口的方式来创建多线程程序

因为Thread是开了两个线程，执行两个任务，所以不能共享资源。
而Runnable是开了两个线程，执行一个任务，所以可以共享资源。

若要定义线程运行顺序，用setPriority（）调整优先级

打开，关闭线程的守护功能：setDaemon()

yield（）：让当前线程暂停，以便让具有相同优先级的其他线程执行。
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
设计模式：
单例的注意事项：
1.构造器设为private。
2.私有static成员变量。
3.公有getInstance（）方法，并在内部进行实例化。
4.多线程安全？synchronized
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

堆和栈有什么区别？
总体来说：栈，主要存放引用和基本数据类型；堆，用来存放new 出来的对象实例，包括对象变量以及对象方法。
栈是跟着线程的，每个线程有一个栈。而堆只有一个，一个jvm只有一个堆内存。

栈也是线程私有的，生命周期与线程相同。java中广义的栈，指的就是此处内存。
每个方法在执行时，都会创建一个栈帧，用于存储局部变量表、操作数栈、动态链接、方法出口等信息。
每个方法调用到执行完毕，都对应一个栈帧在虚拟机栈中入栈出栈的过程。
此处规定了两处异常：
如果线程请求的栈深度大于虚拟机所允许的深度，则抛出stackOverFlowError异常。

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
对象初始化过程？

对象的创建过程。请考虑一个名为Dog 的类：
(1) 类型为Dog 的一个对象首次创建时，或者Dog 类的static 方法／static 字段首次访问时，Java 解释器
必须找到Dog.class（在事先设好的类路径里搜索）。
(2) 找到Dog.class 后（它会创建一个Class 对象，这将在后面学到），它的所有static 初始化模块都会运
行。因此，static 初始化仅发生一次――在Class 对象首次载入的时候。
(3) 创建一个new Dog()时，Dog 对象的构建进程首先会在内存堆（Heap）里为一个Dog 对象分配足够多的存
储空间。
(4) 这种存储空间会清为零，将Dog 中的所有基本类型设为它们的默认值（零用于数字，以及boolean 和
char 的等价设定）。
(5) 进行字段定义时发生的所有初始化都会执行。
(6) 执行构建器

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
常用的垃圾收集算法：

复制算法：（年轻代）
将可用内存分为两块，每次只使用一块儿，这块儿用完了，将还存活的对象复制到另一块，然后把之前的内存空间清理掉。
优点：每次对半个区域进行回收，不用考虑内存碎片等问题。
缺点：内存缩小为原来的一半。

jvm都采用复制算法收集新生代，没必要1:1划分内存空间。
将新生代划分为一个Eden（80%）和两块Survivor（20%）
每次使用Eden和一块Survivor1，回收时将两块存活的对象复制到另一块儿Survivor2上。清理掉Eden和Survivor1.
若拷贝时发现Survivor2空间不够，需要依赖老年代进行分配担保。

标记-整理算法：（老年代）
过程与标记-清除一样，但不是直接对所有对象进行清理，而是让所有存活对象向一端移动，然后清理掉端边界以外的内存。


&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

hashMap/LinkedHashMap和treeMap的区别？？
Hashmap,基于hashtable实现,它根据键的HashCode 值存储数据,根据键可以直接获取它的值，具有很快的访问速度，遍历时，取得数据的顺序是完全随机的。HashMap最多只允许一条记录的键为/Users/sz/文件资料/m面试汇总/java面试题.txtNull;允许多条记录的值为 Null;
LinkedHashMap保存了记录的插入顺序，在用Iterator遍历LinkedHashMap时，先得到的记录肯定是先插入的.也可以在构造时用带参数，按照应用次数排序。在遍历的时候会比HashMap慢，不过有种情况例外，当HashMap容量很大，实际数据较少时，遍历起来可能会比LinkedHashMap慢，因为LinkedHashMap的遍历速度只和实际数据有关，和容量无关，而HashMap的遍历速度和他的容量有关。

TreeMap，基于红黑树实现，能够把它保存的记录根据键排序,默认是按键值的升序排序，也可以指定排序的比较器，当用Iterator 遍历TreeMap时，得到的记录是排过序的。



&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
内存使用率高，如何排查？
用jstat打出各种内存使用情况。
用jmap查看各种基本数据结构的方式

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

确定对象已死的算法？
引用计数：主流jvm中没有用引用计数来管理内存的，因为很难解决对象之间互相引用的问题。
可达性分析：通过一系列GC roots对象作为起点，向下搜索，走过的路径成为引用链。当对象到gc roots没有任何引用链相连，则对象不可用。

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

java中hashmap的构成？
hashmap是数组和链表的结合体。当新建一个hashmap的时候，就会初始化一个数组。

 当我们往hashmap中put元素的时候，先根据key的hash值得到这个元素在数组中的位置（即下标），然后就可以把这个元素放到对应的位置中了。 如果这个元素所在的位子上已经存放有其他元素了，那么在同一个位子上的元素将以链表的形式存放，新加入的放在链头，最先加入的放在链尾。从hashmap 中get元素时，首先计算key的hashcode，找到数组中对应位置的某一元素，然后通过key的equals方法在对应位置的链表中找到需要的元 素。

hashmap的hash方式？：
static   int  indexFor( int  h,  int  length) {  
       return  h & (length- 1 );  
   }

与长度做与操作

初始化hashmap时，最好一次性指定hashmap的大小，size要指定为2的整数次方大小。防止hash碰撞。

什么时候会进行扩容？
当hashmap中的元素个数超过数组大小*loadFactor时，就会进行数组扩容。

为什么扩容会消耗性能？
扩容之后，要进行数据迁移，原有数组中的元素必须重新计算其在新数组中的位置。

equals和hashcode的区别？
equals相等的两个class，hashcode一定相等。
hashcode相等的两个class，equals不一定相等

hashCode的存在主要是用于查找的快捷性，如Hashtable，HashMap等，hashCode是用来在散列存储结构中确定对象的存储地址的；

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&


java的默认classLoader，及作用？
BootStrapClassLoader：用于加载jvm启动的类，之后旧无用了
ExtClassLoader：用于加载java.ext.dirs下面指定的类，并启动AppClassLoader
AppClassLoader：用于加载大部分java默认类。

classLoader默认的加载原则是什么？
父类优先原则

显式加载一个类的方法？
1.通过Class.forName(“class”)
2.通过ClassLoader中的loadClass方法
3.通过ClassLoader中的findSystemClass方法


什么情况需要我们重写ClassLoader？
1.当指定的类不在classpath下时，比如tomcat
2.当类的字节码需要特殊处理时，例如网络传输时对类进行加密解密。
3.当类需要热加载时


-----------------------------------------------------------------------------------------------------------
android：

安卓的虚拟机？dalvik与jvm的区别？

Dalvik 基于寄存器，而 JVM 基于栈。基于寄存器的虚拟机对于更大的程序来说，在它们编译的时候，花费的时间更短。 JVM字节码中，局部变量会被放入局部变量表中，继而被压入堆栈供操作码进行运算，当然JVM也可以只使用堆栈而不显式地将局部变量存入变量表中。Dalvik字节码中，局部变量会被赋给65536个可用的寄存器中的任何一个，Dalvik指令直接操作这些寄存器，而不是访问堆栈中的元素。
2、Dalvik 和 Java 字节码的区别
VM字节码由.class文件组成，每个文件一个class。JVM在运行的时候为每一个类装载字节码。相反的，Dalvik程序只包含一个.dex文件，这个文件包含了程序中所有的类。Java编译器创建了JVM字节码之后，Dalvik的dx编译器删除.class文件，重新把它们编译成Dalvik字节码，然后把它们写进一个.dex文件中。这个过程包括翻译、重构、解释程序的基本元素（常量池、类定义、数据段）。常量池描述了所有的常量，包括引用、方法名、数值常量等。类定义包括了访问标志、类名等基本信息。数据段中包含各种被VM执行的函数代码以及类和函数的相关信息（例如DVM所需要的寄存器数量、局部变量表、操作数堆栈大小），还有实例变量。
3、Dalvik 和 Java 运行环境的区别 　 　
Dalvik 经过优化，允许在有限的内存中同时运行多个虚拟机的实例，并且每一个Dalvik 应用作为一个独立的Linux 进程执行。独立的进程可以防止在虚拟机崩溃的时候所有程序都被关闭。
Dalvik虚拟机在android2.2之后使用JIT （Just-In-Time）技术，与传统JVM的JIT并不完全相同，　
Dalvik虚拟机有自己的 bytecode，并非使用 Java bytecode。

-----------------------------------------------------------------------------------------------------------
storm：
bolt出现OOM的原因汇总：
bolt没有ack信息，造成信息在内存中越积越多，造成oom。
bolt所属的业务数据过多，超过了storm的限制，造成gc。
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

若读取多个spout的数据源，例如读取hbase的多个partition，如何在worker之间进行分配？？

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
如何追踪一条信息的处理？tuple树
 当一个tuple被创建， 不管是spout还是bolt创建的， 它会被赋予一个64位的id，而acker就是利用这个id去跟踪所有的tuple的。每个tuple知道它的祖宗的id(从spout发出来的那个tuple的id), 每当你新发射一个tuple， 它的祖宗id都会传给这个新的tuple。所以当一个tuple被ack的时候，它会发一个消息给acker，告诉它这个tuple树发生了怎么样的变化。具体来说就是：它告诉acker： 我呢已经完成了， 我有这些儿子tuple, 你跟踪一下他们吧。
storm使用一致性哈希来把一个spout-tuple-id对应到acker， 因为每一个tuple知道它所有的祖宗的tuple-id， 所以它自然可以算出要通知哪个acker来ack。

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

如何保证一条消息被成功的处理。例：若spout或bolt处理失败，如何得知？
每次spout发射消息成功后，都会调用ack。失败会调用fail。
首先初始化两个queue，一个发送queue，一个发送失败queue。
每次要发射一个tuple，都产生一个唯一的tupleID。并将其加入到发送queue中。
发送queue和发送失败queue中的消息，会被定期发送。     
若ack被调用，则将此tupleID从发送queue和发送失败queue中删除。表示发射成功。
若fail被调用，则将此msg加入发送失败queue中。msgID的失败次数加一，并判断是否到达最大失败次数。若是则抛出异常或打印错误日志等。

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
什么是anchoring？？作用如何？？
在msg中添加原始spout的引用。
此时，如果任何bolts ack或failed，所有的spouts都会被通知到。





-----------------------------------------------------------------------------------------------------------

hadoop：
hadoop版本，为什么用此版本
做过什么优化？知道有什么优化？
集群规模，是否有运维经验？


hadoop的资源管理？
map slot和reduce slot.由一个插拔式调度器来完成。
默认当map task完成5%时，开始reduce的任务。

map slot和reduce slot这样的资源分配方式，有何问题？
当map完成5%，然后进行reduce的slot时，reduce等待所有的map完成，可能会占据大量的slot资源。


初级：

详述map 和reduce过程中，都做了什么东东？
Map:
record reader:
输入单元为split，split是一个逻辑概念，只包含一些元数据信息，例如数据起始位置，长度，所在节点等，每个split会交由一个map task处理，reader将split中的多个block解析成一个个key/value对。
map：
一次调用用户自定义的map函数进行处理
partition：
根据默认的partition或用户自定义的函数，将临时结果分成若干个partition，每个partition将被一个ReduceTask处理，并将临时结果存放到本地磁盘上。

Reduce：
shuffle：
从远程节点上读取mapTask的中间结果
sort：
按照key对key/value进行排序，注意只有key排序。value无序。
reduce ：
调用用户自定义的reduce结果
output collect：
将最终结果写入到HDFS上。



给定一堆帖子及发帖时间，发帖作者，求论坛所有用户的最早发帖时间，最晚发帖时间，及发帖数目。
如何优化？
用combiner进行本地优化，提升性能。

进阶：
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
secondNamenode的作用？
不是用来做namenode的备份，而是为了定期合并fsimage以及editlog，因为namenode不会对这些进行合并。

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
有两张表：
全公司员工信息表：姓名，年龄。。。（较小）
全公司员工薪水表：姓名，薪水。。。。（较大）
求公司30岁-40岁之间的员工薪水情况表。

1.先从HDFS中load数据，训练bloom Filter
2.map时根据bloomFilter过滤表1和表2数据
3.reduce开始join双表

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
什么是hadoop 的Distributed Cache？主要功能？使用方式
将作业文件分发到个taskTracker上。
命令行-file，和API的形式。
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
什么是Hadoop Streaming？pipes？
Streaming：利用其它语言编写mapper和reducer，利用标准输入输出，实现java与其他脚本之间的通信
pipes：让c++与java通过socket进行通信的方式。
java端实现mapred作业，c++端通过socket将输入的key和value传递给可执行文件。
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
求从一堆数据中求top N的记录
1）数据量不大，如何展开？  每个map输出top N，然后一个reduce输出。
2）数据量相当大：  第一个map/red统计频次，第二个map/red统计top N。
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
用hadoop进行全排序，说出思路即可。
分析阶段决定范围，排序阶段真正的去排序。
分析阶段就是对数据的随机取样。分区是跟据这个随机样本进行的。原理是，能把随机样本均匀分割的分区也应该把大数据集均匀分割
・mapper做一个简单的随机取样。
・这里只使用一个reducer。收集排序的key进入一个排序列表，然后精简列表数据得到数据范围的边界，形成一个分区文件


排序阶段时相对简单的使用自定义partitioner的MapReduce程序，结构如下：
・mapper抽取排序key，跟分析阶段方式相同。但value会被赋予记录本身。
・自定义的partitioner用于加载分区文件。在hadoop里，可以使用TotalOrderPartitioner,是专为此设计的类。它获取这个分区文件的数据范围，来决定每条记录被发到哪个reducer。
・这里reducer比较简单。Shuffle和sort做了繁重的工作。Reduce只是简单的把值输出。Reducer的个数应该等于TotalOrderPartitioner 的分区的个数。

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
hadoop任务的运行过程：
1.用户在gateway上提交任务，jar包被upload到hdfs上。然后jobclient通过RPC通知jobtracker。
2.jobtracker为map和reduce分别指定tasktracker，并跟踪整个任务执行过程。
3.tasktracker执行任务，jvm启动和资源隔离。
4.执行任务，每个task的进度都会通过RPC汇报给tasktracker，在汇报给jobtracker
5.任务完成。
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
map/red编程题：给出少量用户数据和大量评论数据，用用户数据丰富评论内容。

将少量数据放入distributedcache，加载进内存。
用map进行join
&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
map/red编程题：给出大量用户数据和大量评论数据，用用户数据丰富评论数据
用户数据和评论数据的输入文件相同，相同的外键key的记录也包含在相同的split里面。

用CompositeInputFormat解析输入，将相同的外键key的value合并。
map：合并多个value数值，collect输出。

-----------------------------------------------------------------------------------------------------------
mesos：
与yarn在调度上的不同？语言的不同？
mesos：分布式调度、c++
yarn：集中式调度、java
集中式调度的好处是简单，高效，由于Master掌握整个集群的资源分配状况，可以做一些全局性的优化决策，集中式调度的问题在于需要支持足够灵活而具有可扩展性的个性化调度语义来满足目前以及未来各个接入应用特殊的资源分配需求，而且由于全部分配逻辑都集中在Master，Master的可扩展性和健壮性也会成为瓶颈。
分布式调度除了具有更好的横向扩展性以外，也有两个问题，一个是可能无法做到全局最优，同时会破坏公平性，也很难实现抢占；

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

如何进行资源隔离？
在资源隔离上，二者底层都依赖Cgroup实现，目前做的比较成熟的是CPU和内存的进程级隔离，对于近期炙手可热的容器技术Docker，Mesos也是积极的跟进整合中。


&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&
slave与framework介绍？描述一次资源分配的过程？
Slave是运行在物理或虚拟服务器上的Mesos守护进程，是Mesos集群的一部分。
Framework由调度器（Scheduler）应用程序和任务执行器（Executor）组成，被注册到Mesos以使用Mesos集群中的资源。

Slave 1向Master汇报其空闲资源：4个CPU、4GB内存。然后，Master触发分配策略模块，得到的反馈是Framework 1要请求全部可用资源。
Master向Framework 1发送资源邀约，描述了Slave 1上的可用资源。
Framework的调度器（Scheduler）响应Master，需要在Slave上运行两个任务，第一个任务分配<2 CPUs, 1 GB RAM>资源，第二个任务分配<1 CPUs, 2 GB RAM>资源。
最后，Master向Slave下发任务，分配适当的资源给Framework的任务执行器（Executor）,接下来由执行器启动这两个任务（如图中虚线框所示）。 此时，还有1个CPU和1GB的RAM尚未分配，因此分配模块可以将这些资源供给Framework 2。

-----------------------------------------------------------------------------------------------------------


spark：
任务调度过程？
主要分为三部分：创建RDD对象，DAG调度器创建执行计划，Task调度器分配任务并调度Worker开始运行。



什么是窄依赖、宽依赖，为什么要如此划分？
窄依赖 (narrowdependencies) 和宽依赖 (widedependencies) 。窄依赖是指 父 RDD 的每个分区都只被子 RDD 的一个分区所使用 。相应的，那么宽依赖就是指父 RDD 的分区被多个子 RDD 的分区所依赖。例如， map 就是一种窄依赖，而 join 则会导致宽依赖
?　　这种划分有两个用处：
首先，窄依赖被划分到一个stage中，支持在一个结点上管道化执行。例如基于一对一的关系，可以在 filter 之后执行 map 。
其次，窄依赖支持更高效的故障还原。因为对于窄依赖，只有丢失的父 RDD 的分区需要重新计算。而对于宽依赖，一个结点的故障可能导致来自所有父 RDD 的分区丢失，因此就需要完全重新执行。因此对于宽依赖，Spark 会在持有各个父分区的结点上，将中间数据持久化来简化故障还原，就像 MapReduce 会持久化 map 的输出一样。

&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&&

spark的shuffle，相比于hadoop有什么优化？
spark的shuffle过程：
1.map任务为每个reduce任务创建一个bucket，假设有M个map任务，R个reduce任务，则会有M*R个bucket。
2.map任务将产生的中间结果按照partition写入不同的bucket中
3.reduce任务从本地或远端的map任务所在的blockManager获取相应的bucket作为输入。
存在问题：
1.在bucket本身不大，但shuffle频繁的场景下，会不断创建bucket文件，导致磁盘IO频繁。
2.map中间结果首先存入内存，然后写入磁盘，对于内存的开销很大。

优化过程：
1.map给每个reduce任务的bucket合并到同一个文件中，解决了bucket数量多但体积不大的IO性能瓶颈问题。
2.map任务逐条输出计算结果，而不是一次性输出到内存，并对中间结果进行聚合。
3.利用缓存进行溢出判断，当超过大小则写入内存。
4.reduce对拉渠道的map中间结果逐条读取，而不是一次性读入内存，并在内存中进行聚合和排序，大大减小数据占用的内存。
5.reduce任务将要拉取的block按照blockManager地址划分，将同一个blockManager地址中的block累计为少量网络请求。


毕玄整理的一些Java问题：https://www.aliway.com/read.php?spm=a1z2e.8101737.list.2.199f6a6coaaElA&tid=447460